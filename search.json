[
  {
    "objectID": "woche3.html",
    "href": "woche3.html",
    "title": "Woche 3",
    "section": "",
    "text": "Code\nimport math\nfrom typing import Tuple\nfrom collections import namedtuple\nimport plotly.graph_objects as go\nimport plotly.io as pio\n\n\nBENE_COLORS_DARK: Tuple[str, ...] = (\n    \"#47476b\",\n    \"#6B5706\",\n    \"#206260\",\n    \"#93003a\",\n    \"#215F80\",\n    \"#973C2B\",\n    \"#008381\",\n    \"#6d3d3d\",\n    \"#595865\",\n)\npio.templates[\"bene\"] = go.layout.Template(layout=go.Layout(colorway=BENE_COLORS_DARK))\npio.templates.default = \"plotly_white+bene\"\n\nFourByFourTable = namedtuple(\"FourByFourTable\", [\"a\", \"b\", \"c\", \"d\"])\n\ndef berechne_RR (four_x_four: FourByFourTable) -&gt; float:\n    return (four_x_four.a / (four_x_four.a + four_x_four.b)) / (four_x_four.c / (four_x_four.c + four_x_four.d))\n\ndef berechne_SE_ln_RR (four_x_four: FourByFourTable) -&gt; float:\n    return math.sqrt((four_x_four.b/(four_x_four.a*(four_x_four.a+four_x_four.b)))+(four_x_four.d/(four_x_four.c*(four_x_four.c+four_x_four.d))))\n\ndef berechne_95_CI (four_x_four: FourByFourTable) -&gt; Tuple[float, float]:\n    RR = berechne_RR(four_x_four)\n    ln_RR = math.log(RR)\n    SE_ln_RR = berechne_SE_ln_RR(four_x_four)\n    z = 1.96  # 95% confidence interval\n    lower_ln = ln_RR - z * SE_ln_RR\n    upper_ln = ln_RR + z * SE_ln_RR\n    lower_CI = math.exp(lower_ln)\n    upper_CI = math.exp(upper_ln)\n    return lower_CI, upper_CI",
    "crumbs": [
      "Woche 3"
    ]
  },
  {
    "objectID": "woche3.html#aufgabe-2",
    "href": "woche3.html#aufgabe-2",
    "title": "Woche 3",
    "section": "Aufgabe 2",
    "text": "Aufgabe 2\n\n\nCode\nfour_x_four = FourByFourTable(12, 288, 20, 180)\n\n\n\n1. b\n\\(\\widehat{SE}\\):\n\n\nCode\nf\"{berechne_SE_ln_RR(four_x_four):.2f}\"\n\n\n'0.35'\n\n\n\n\nCode\n\"{:.2f}, {:.2f}\".format(*berechne_95_CI(four_x_four))\n\n\n'0.20, 0.80'\n\n\n\n\n\n\n\nCode\nRR = berechne_RR(four_x_four)\nCI = berechne_95_CI(four_x_four)\n\nfour_x_four_half = FourByFourTable(6, 144, 10, 90)\nRR_half = berechne_RR(four_x_four_half)\nCI_half = berechne_95_CI(four_x_four_half)\n\nfour_x_four_10 = FourByFourTable(120, 2880, 200, 1800)\nRR_10 = berechne_RR(four_x_four_10)\nCI_10 = berechne_95_CI(four_x_four_10)\n\nfig = go.Figure()\ny_axis = [\"n=2500\", \"n=500\", \"n=250\"]\nfig.add_trace(\n    go.Scatter(\n        x=[RR_10, RR, RR_half],\n        y=y_axis,\n        mode=\"markers\",\n        marker=dict(size=10, symbol=\"square\"),\n        error_x=dict(\n            type=\"data\",\n            symmetric=False,\n            array=[CI_10[1] - RR_10, CI[1] - RR, CI_half[1] - RR_half],\n            arrayminus=[RR_10 - CI_10[0], RR - CI[0], RR_half - CI_half[0]],\n        ),\n    )\n)\nfig.add_vline(x=1)\nfig.add_vline(x=0.7, line_dash=\"dash\")\nfig.add_vline(x=1.5, line_dash=\"dash\")\n\nfig.update_layout(xaxis=dict(range=[0, 2]), height=150)\n\nfig.show()",
    "crumbs": [
      "Woche 3"
    ]
  },
  {
    "objectID": "woche3.html#aufgabe-4",
    "href": "woche3.html#aufgabe-4",
    "title": "Woche 3",
    "section": "Aufgabe 4",
    "text": "Aufgabe 4\n\na\n\n\nCode\nln_RR = [3.5175, 0.7129, 1.5581, 1.1410, 1.6332]\nSE_ln_RR = [1.4210, 1.2122, 0.5533, 0.3818, 0.3436]\n# Berechnung der Gewichte w_i\nweights = [1 / (se ** 2) for se in SE_ln_RR]\n\n# Berechnung von Summe(w_i * ln(RR)) und Summe(w_i)\nsum_w_lnRR = sum(w * lnrr for w, lnrr in zip(weights, ln_RR))\nsum_w = sum(weights)\n# Berechnung des gepoolten ln(RR)\nln_RR_pool = sum_w_lnRR / sum_w\nRR_pool = math.exp(ln_RR_pool)\n\nf\"{RR_pool:.2f}\"\n\n\n'4.33'\n\n\n\n\nb\n\n\nCode\nf\"{weights[4]:.2f}\"\n\n\n'8.47'",
    "crumbs": [
      "Woche 3"
    ]
  },
  {
    "objectID": "woche3.html#aufgabe-5",
    "href": "woche3.html#aufgabe-5",
    "title": "Woche 3",
    "section": "Aufgabe 5",
    "text": "Aufgabe 5\n\na\n\n\nCode\nfour_x_four = FourByFourTable(\n    round(295 * 0.197),\n    round(295 - (295 * 0.197)),\n    round(143 * 0.194),\n    round(143 - (143 * 0.194)),\n)\nfour_x_four\n\n\nFourByFourTable(a=58, b=237, c=28, d=115)\n\n\n\n\nb\n\n\nCode\nRR = berechne_RR(four_x_four)\n\nf\"{RR:.2f}\"\n\n\n'1.00'\n\n\n\n\nc\n\n\nCode\nCI = berechne_95_CI(four_x_four)\n\nf\"{CI[0]:.2f}, {CI[1]:.2f}\"\n\n\n'0.67, 1.50'",
    "crumbs": [
      "Woche 3"
    ]
  },
  {
    "objectID": "woche2.html",
    "href": "woche2.html",
    "title": "Woche 2",
    "section": "",
    "text": "Code\nimport math\nimport numpy as np\nimport scipy.interpolate as interp\nfrom typing import Tuple\nfrom collections import namedtuple\nimport plotly.graph_objects as go\nimport plotly.io as pio\n\n\nBENE_COLORS_DARK: Tuple[str, ...] = (\n    \"#47476b\",\n    \"#6B5706\",\n    \"#206260\",\n    \"#93003a\",\n    \"#215F80\",\n    \"#973C2B\",\n    \"#008381\",\n    \"#6d3d3d\",\n    \"#595865\",\n)\npio.templates[\"bene\"] = go.layout.Template(layout=go.Layout(colorway=BENE_COLORS_DARK))\npio.templates.default = \"plotly_white+bene\"\n\nFourByFourTable = namedtuple(\"FourByFourTable\", [\"a\", \"b\", \"c\", \"d\"])\n\n\ndef berechne_ppv(sens: float, spez: float, praev: float) -&gt; float:\n    return (sens * praev) / (sens * praev + (1 - spez) * (1 - praev))\n\n\ndef berechne_npv(sens: float, spez: float, praev: float) -&gt; float:\n    return (spez * (1 - praev)) / (spez * (1 - praev) + (1 - sens) * praev)\n\n\ndef berechne_95_ci(s: float, n: int) -&gt; tuple:\n    lower = s - 1.96 * math.sqrt(s * (1 - s) / n)\n    upper = s + 1.96 * math.sqrt(s * (1 - s) / n)\n    return lower, upper\n\n\ndef berechne_se_4x4(four_by_four_table: FourByFourTable) -&gt; float:\n    return four_by_four_table.a / (four_by_four_table.a + four_by_four_table.c)\n\n\ndef berechne_sp_4x4(four_by_four_table: FourByFourTable) -&gt; float:\n    return four_by_four_table.d / (four_by_four_table.b + four_by_four_table.d)",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#aufgabe-2-glaukom",
    "href": "woche2.html#aufgabe-2-glaukom",
    "title": "Woche 2",
    "section": "Aufgabe 2: Glaukom",
    "text": "Aufgabe 2: Glaukom\n\nPrävalenz: 0.9 % = 0.009\nSensitivität: 85 % = 0.85\nSpezifität: 90 % = 0.90\n\n\n\nCode\nprevalence = 0.009\nsensitivity = 0.85\nspecificity = 0.90",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#section",
    "href": "woche2.html#section",
    "title": "Woche 2",
    "section": "2",
    "text": "2\n\n\nCode\nppv_screening = berechne_ppv(sensitivity, specificity, prevalence)\nppv_screening\n\n\n0.07166276346604215\n\n\n\n\nCode\nnpv_screening = berechne_npv(sensitivity, specificity, prevalence)\nnpv_screening\n\n\n0.9984886649874056",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#section-1",
    "href": "woche2.html#section-1",
    "title": "Woche 2",
    "section": "3",
    "text": "3\n\n\nCode\npopulation = 100000\ntrue_positives = sensitivity * prevalence * population\nfalse_negatives = (1 - sensitivity) * prevalence * population\nfalse_positives = (1 - specificity) * (1 - prevalence) * population\ntrue_negatives = specificity * (1 - prevalence) * population\ntrue_positives, false_negatives, false_positives, true_negatives\n\n\n(764.9999999999999, 135.0, 9909.999999999998, 89190.0)",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#aufgabe-3",
    "href": "woche2.html#aufgabe-3",
    "title": "Woche 2",
    "section": "Aufgabe 3",
    "text": "Aufgabe 3",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#section-2",
    "href": "woche2.html#section-2",
    "title": "Woche 2",
    "section": "1",
    "text": "1\n\n\nCode\n# Gegebene Werte aus der Studie (Katz et al., 1993)\nsensitivity_study = 0.836  # Sensitivität des Suprathreshold Visual Field Test\nspecificity_study = 0.749  # Spezifität des Suprathreshold Visual Field Test\n\n# Populationsgröße in der Studie\ntotal_population_study = 5341  \n\n# Anzahl tatsächlich kranker (Glaukomfälle)\ntrue_cases_study = 146  \n\n# Anzahl gesunder Personen\nhealthy_cases_study = total_population_study - true_cases_study  \n\n# Berechnung der Prävalenz in der Studienpopulation\nprevalence_study = true_cases_study / total_population_study  \n\n# Berechnung des positiven prädiktiven Werts (PPV)\nppv_study = berechne_ppv(sensitivity_study, specificity_study, prevalence_study)\n\n# Berechnung des negativen prädiktiven Werts (NPV)\nnpv_study = berechne_npv(sensitivity_study, specificity_study, prevalence_study)\n\nppv_study, npv_study\n\n\n(0.08559320785890051, 0.9938840341977099)\n\n\nPrävalenz bei beiden Test nacheinander. Prävalenz des zweiten Tests ist PPV des ersten Tests.\n\n\nCode\nppv_study_after_positive_screening = berechne_ppv(sensitivity_study, specificity_study, ppv_screening)\nnpv_study_after_positive_screening = berechne_npv(sensitivity_study, specificity_study, ppv_screening)\nppv_study_after_positive_screening, npv_study_after_positive_screening\n\n\n(0.20452517628999506, 0.9833784884837806)",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#section-3",
    "href": "woche2.html#section-3",
    "title": "Woche 2",
    "section": "2",
    "text": "2\n\na\n\n\nCode\n1-npv_study\n\n\n0.006115965802290124\n\n\n\n\nc\n\n\nCode\n1-ppv_study\n\n\n0.9144067921410994",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#section-4",
    "href": "woche2.html#section-4",
    "title": "Woche 2",
    "section": "3",
    "text": "3\n\n\nCode\nberechne_95_ci(sensitivity_study, total_population_study), berechne_95_ci(specificity_study, total_population_study)\n\n\n((0.8260695290539164, 0.8459304709460835),\n (0.7373715306646761, 0.7606284693353239))",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#aufgabe-4",
    "href": "woche2.html#aufgabe-4",
    "title": "Woche 2",
    "section": "Aufgabe 4",
    "text": "Aufgabe 4",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#section-5",
    "href": "woche2.html#section-5",
    "title": "Woche 2",
    "section": "2",
    "text": "2\n\n\nCode\ncutoff_1_44 = FourByFourTable(53, 285, 0, 182)\ncutoff_1_44_se = berechne_se_4x4(cutoff_1_44)\ncutoff_1_44_sp = berechne_sp_4x4(cutoff_1_44)\ncutoff_1_44_se, cutoff_1_44_sp, 1-cutoff_1_44_sp\n\n\n(1.0, 0.3897216274089936, 0.6102783725910064)\n\n\n\n\nCode\ncutoff_1_14 = FourByFourTable(50, 187, 3, 280)\ncutoff_1_14_se = berechne_se_4x4(cutoff_1_14)\ncutoff_1_14_sp = berechne_sp_4x4(cutoff_1_14)\ncutoff_1_14_se, cutoff_1_14_sp, 1-cutoff_1_14_sp\n\n\n(0.9433962264150944, 0.5995717344753747, 0.4004282655246253)\n\n\n\n\nCode\ncutoff_1_02 = FourByFourTable(43, 112, 10, 355)\ncutoff_1_02_se = berechne_se_4x4(cutoff_1_02)\ncutoff_1_02_sp = berechne_sp_4x4(cutoff_1_02)\ncutoff_1_02_se, cutoff_1_02_sp, 1-cutoff_1_02_sp\n\n\n(0.8113207547169812, 0.7601713062098501, 0.23982869379014993)\n\n\n\n\nCode\ncutoff_0_8 = FourByFourTable(34, 47, 19, 420)\ncutoff_0_8_se = berechne_se_4x4(cutoff_0_8)\ncutoff_0_8_sp = berechne_sp_4x4(cutoff_0_8)\ncutoff_0_8_se, cutoff_0_8_sp, 1-cutoff_0_8_sp\n\n\n(0.6415094339622641, 0.8993576017130621, 0.10064239828693788)\n\n\n\n\nCode\ncutoff_0_6 = FourByFourTable(23, 5, 30, 462)\ncutoff_0_6_se = berechne_se_4x4(cutoff_0_6)\ncutoff_0_6_sp = berechne_sp_4x4(cutoff_0_6)\ncutoff_0_6_se, cutoff_0_6_sp, 1-cutoff_0_6_sp\n\n\n(0.4339622641509434, 0.9892933618843683, 0.010706638115631661)\n\n\n\n\nCode\nspecificity = np.array([\n    0,\n    1 - cutoff_0_6_sp,\n    1 - cutoff_0_8_sp,\n    1 - cutoff_1_02_sp,\n    1 - cutoff_1_14_sp,\n    1 - cutoff_1_44_sp,\n    1,\n])\nsensitivity = np.array([\n    0,\n    cutoff_0_6_se,\n    cutoff_0_8_se,\n    cutoff_1_02_se,\n    cutoff_1_14_se,\n    cutoff_1_44_se,\n    1,\n])\ncutoffs = np.array([0, 0.6, 0.8, 1.02, 1.14, 1.44, 2])\n\n# Initialize variables\nbest_cutoff = None\nmax_j = -np.inf\n\n# Loop through each segment between two cutoffs\nfor i in range(len(cutoffs) - 1):\n    C1, C2 = cutoffs[i], cutoffs[i + 1]\n    S1, S2 = sensitivity[i], sensitivity[i + 1]\n    P1, P2 = specificity[i], specificity[i + 1]\n    \n    # Compute the slope for linear interpolation\n    sensitivity_slope = (S2 - S1) / (C2 - C1)\n    specificity_slope = (P2 - P1) / (C2 - C1)\n\n    # Solve for cutoff that maximizes Youden's J in this segment\n    # J(c) = (S1 + sensitivity_slope * (c - C1)) + (P1 + specificity_slope * (c - C1)) - 1\n    # dJ/dc = sensitivity_slope + specificity_slope = 0\n    if sensitivity_slope + specificity_slope != 0:  # Avoid division by zero\n        optimal_c = C1 - (S1 + P1 - 1) / (sensitivity_slope + specificity_slope)\n\n        # Ensure the found cutoff is within the segment\n        if C1 &lt;= optimal_c &lt;= C2:\n            optimal_j = (S1 + sensitivity_slope * (optimal_c - C1)) + \\\n                        (P1 + specificity_slope * (optimal_c - C1)) - 1\n            \n            # Update the best cutoff if this J value is better\n            if optimal_j &gt; max_j:\n                max_j = optimal_j\n                best_cutoff = optimal_c\n                best_sensitivity = sensitivity_slope\n                best_specificity = specificity_slope\n\nprint(f\"Optimal Cutoff (linear): {best_cutoff:.3f}\")\n\n\nOptimal Cutoff (linear): 0.984\n\n\n\n\nCode\nroc_x = [\n    0,\n    1 - cutoff_0_6_sp,\n    1 - cutoff_0_8_sp,\n    1 - cutoff_1_02_sp,\n    1 - cutoff_1_14_sp,\n    1 - cutoff_1_44_sp,\n    1,\n]\nroc_y = [\n    0,\n    cutoff_0_6_se,\n    cutoff_0_8_se,\n    cutoff_1_02_se,\n    cutoff_1_14_se,\n    cutoff_1_44_se,\n    1,\n]\nroc_labels = [\"\", \"0.6 mm²\", \"0.8 mm²\", \"1.02 mm²\", \"1.14 mm²\", \"1.44 mm²\", \"\"]\n\nfig = go.Figure()\nfig.add_shape(\n    type=\"line\", line=dict(dash=\"dash\"), fillcolor=\"black\", x0=0, x1=1, y0=0, y1=1\n)\nfig.add_trace(\n    go.Scatter(\n        x=roc_x,\n        y=roc_y,\n        text=roc_labels,\n        textposition=\"bottom right\",\n        mode=\"lines+markers+text\",\n        fill=\"tozeroy\",\n        fillcolor=\"rgba(71, 71, 107, 0.2)\",\n    )\n)\nfig.update_layout(\n    title=\"ROC Curve RNFL Area\",\n    xaxis_title=\"1 - Spezifität\",\n    yaxis_title=\"Sensitivität\",\n    xaxis=dict(range=[0, 1]),\n    yaxis=dict(range=[0, 1], scaleanchor=\"x\", scaleratio=1),\n)\nfig.show()",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#aufgabe-7",
    "href": "woche2.html#aufgabe-7",
    "title": "Woche 2",
    "section": "Aufgabe 7",
    "text": "Aufgabe 7",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche2.html#section-6",
    "href": "woche2.html#section-6",
    "title": "Woche 2",
    "section": "2",
    "text": "2\n\n\nCode\na, b, c, d = 30, 366, 56, 352\n\np1 = a / (a + b)\np2 = c / (c + d)\n\np1, p2\n\n\n(0.07575757575757576, 0.13725490196078433)\n\n\n\n\nCode\np = (a + c) / (a + b + c + d)\nSE = math.sqrt((p * (1 - p) / (a + b)) + (p * (1 - p) / (c + d)))\n\nSE\n\n\n0.02180247257454774\n\n\n\n\nCode\nT = (p1 - p2) / SE\nT\n\n\n-2.820658344732913",
    "crumbs": [
      "Woche 2"
    ]
  },
  {
    "objectID": "woche4.html",
    "href": "woche4.html",
    "title": "Woche 4",
    "section": "",
    "text": "Es wird der Pima Indians Diabetes Database-Datensatz [1] von Kaggle verwendet.\n\n\n\nDiabetes mellitus Typ 2 ist eine chronische Erkrankung mit hoher Prävalenz, insbesondere bei bestimmten Bevölkerungsgruppen.\nPima-Indianerinnen weisen eine der weltweit höchsten Raten an Typ-2-Diabetes auf.\nDie Identifikation von Risikofaktoren kann zur Prävention und Früherkennung beitragen.\nDer verfügbare Datensatz ermöglicht die Analyse potenzieller Zusammenhänge zwischen verschiedenen Gesundheitsparametern und dem Auftreten von Diabetes.",
    "crumbs": [
      "Woche 4"
    ]
  },
  {
    "objectID": "woche4.html#einleitung",
    "href": "woche4.html#einleitung",
    "title": "Woche 4",
    "section": "",
    "text": "Es wird der Pima Indians Diabetes Database-Datensatz [1] von Kaggle verwendet.\n\n\n\nDiabetes mellitus Typ 2 ist eine chronische Erkrankung mit hoher Prävalenz, insbesondere bei bestimmten Bevölkerungsgruppen.\nPima-Indianerinnen weisen eine der weltweit höchsten Raten an Typ-2-Diabetes auf.\nDie Identifikation von Risikofaktoren kann zur Prävention und Früherkennung beitragen.\nDer verfügbare Datensatz ermöglicht die Analyse potenzieller Zusammenhänge zwischen verschiedenen Gesundheitsparametern und dem Auftreten von Diabetes.",
    "crumbs": [
      "Woche 4"
    ]
  },
  {
    "objectID": "woche4.html#studiendesign",
    "href": "woche4.html#studiendesign",
    "title": "Woche 4",
    "section": "2 Studiendesign",
    "text": "2 Studiendesign\n\n2.1 Beschreibung des Studientyps\nCross-Sectional Study (Querschnittsstudie): Der Datensatz enthält Informationen über Gesundheitsparameter und den Diabetesstatus, die zu einem bestimmten Zeitpunkt erfasst wurden.",
    "crumbs": [
      "Woche 4"
    ]
  },
  {
    "objectID": "woche4.html#fragestellung-und-ziele",
    "href": "woche4.html#fragestellung-und-ziele",
    "title": "Woche 4",
    "section": "3 Fragestellung und Ziele",
    "text": "3 Fragestellung und Ziele\n\n3.1 Konkrete Forschungsfragen oder Hypothesen.\n\\(H_0\\): Es besteht keine Assoziation zwischen dem Body-Mass-Index (BMI) und dem Auftreten von Typ-2-Diabetes bei Pima-Indianerinnen.\n\n\n3.2 Primäres Ziel der Studie und eventuelle sekundäre Ziele.\nPrimäres Ziel: Untersuchung der Beziehung zwischen BMI und Diabetes.\nSekundäre Ziele: Untersuchung der weiteren im Datensatz enthaltenen Gesundheitsparameter und deren mögliche Assoziation mit Diabetes.",
    "crumbs": [
      "Woche 4"
    ]
  },
  {
    "objectID": "woche4.html#endpunkte",
    "href": "woche4.html#endpunkte",
    "title": "Woche 4",
    "section": "4 Endpunkte",
    "text": "4 Endpunkte\n\n4.1 Primärer Endpunkt (Zielvariable): Definition\n\nOdds-Ratio für das Auftreten von Diabetes-Typ-2 in Bezug auf den Body-Mass-Index (BMI).\n\n\n\n4.2 Sekundäre Endpunkte: Definition\n\nMesswerte der unabhängigen Variablen:\n\nBody-Mass-Index (BMI)\nAnzahl der Schwangerschaften\nGlukosekonzentration im Plasma\nBlutdruck\nHautdicke (Trizeps)\nInsulin\nPedigree-Faktor\nAlter",
    "crumbs": [
      "Woche 4"
    ]
  },
  {
    "objectID": "woche4.html#studienpopulation-und-analysierte-subgruppen",
    "href": "woche4.html#studienpopulation-und-analysierte-subgruppen",
    "title": "Woche 4",
    "section": "5 Studienpopulation und analysierte Subgruppen",
    "text": "5 Studienpopulation und analysierte Subgruppen\n\n5.1 Population\nPima-Indianerinnen ab 21 Jahren: 768.\n\n\n5.2 Subgruppen\n\nAltersgruppen: z.B. &lt;30 Jahre, 30–40 Jahre, &gt;40 Jahre.\nBMI-Kategorien: Normalgewicht, Übergewicht, Adipositas.\nAnzahl der Schwangerschaften: 0, 1–3, &gt;3 Schwangerschaften.",
    "crumbs": [
      "Woche 4"
    ]
  },
  {
    "objectID": "woche4.html#analyse-primärer-sekundäre-entpunkte",
    "href": "woche4.html#analyse-primärer-sekundäre-entpunkte",
    "title": "Woche 4",
    "section": "6 Analyse (primärer & sekundäre Entpunkte)",
    "text": "6 Analyse (primärer & sekundäre Entpunkte)\n\n6.1 Beschreibung der geeigneten Methode\n\nDeskriptive Statistik: Mittelwerte, Standardabweichungen, Verteilungsanalysen der Variablen.\nBivariate Analysen: Chi-Quadrat-Test für kategoriale Variablen, t-Test oder ANOVA für kontinuierliche Variablen.\nLogistische Regression zur Bestimmung der Odds Ratios für das Auftreten von Diabetes in Bezug auf Risikofaktoren.\nKonfidenzintervalle und p-Werte zur Beurteilung der statistischen Signifikanz.\n\n\n\n6.2 Muss nach möglichen Confoundern adjustiert werden?\n\nJa, berücksichtigung von Wechselwirkungen zwischen Variablen.\n\n\n\n6.3 Umgang mit fehlenden Daten\nAusschluss von Fällen mit fehlenden Werten in Schlüsselvariablen, falls erforderlich.",
    "crumbs": [
      "Woche 4"
    ]
  },
  {
    "objectID": "woche4.html#berichterstattung-und-interpretation",
    "href": "woche4.html#berichterstattung-und-interpretation",
    "title": "Woche 4",
    "section": "7 Berichterstattung und Interpretation",
    "text": "7 Berichterstattung und Interpretation\n\n7.1 Mögliche Präsentation der Ergebnisse (Tabellen, Grafiken)\n\nTabellen:\n\nDeskriptive Statistiken der Studienpopulation.\nErgebnisse der logistischen Regression (Odds Ratios, Konfidenzintervalle, p-Werte).\n\nGrafiken:\n\nBoxplots oder Histogramme zur Visualisierung von Verteilungen der Variablen.\nForest Plot für die Darstellung der Odds Ratios.\n\n\n\n\n7.2 Hinweise auf Limitation und mögliche Verzerrungen\n\nQuerschnittsdesign ermöglicht keine Aussage über Kausalität.\nSelektionsbias durch spezifische Population (Ergebnisse nicht ohne Weiteres auf andere Gruppen übertragbar).\nMessfehler oder Ungenauigkeiten in den erhobenen Daten.\nConfounder: Nicht berücksichtigte Variablen (z.B. Lebensstil).\nInformationsbias durch Selbstangaben oder fehlerhafte Messungen.",
    "crumbs": [
      "Woche 4"
    ]
  },
  {
    "objectID": "woche5.html",
    "href": "woche5.html",
    "title": "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen",
    "section": "",
    "text": "Diese Analyse untersucht den Zusammenhang zwischen Body-Mass-Index (BMI) und dem Auftreten von Diabetes-Typ-2 bei Pima-Indianerinnen basierend auf einem Datensatz von Kaggle [1]. Die Haupthypothese ist:\n\\(H_0\\): Es besteht keine Assoziation zwischen dem Body-Mass-Index (BMI) und dem Auftreten von Diabetes-Typ-2 bei Pima-Indianerinnen.\nNeben dem primären Ziel der BMI-Analyse werden auch sekundäre Endpunkte wie Glukosekonzentration, Blutdruck, Hautdicke, Insulin, Alter und Schwangerschaftsanzahl untersucht.",
    "crumbs": [
      "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen"
    ]
  },
  {
    "objectID": "woche5.html#einleitung",
    "href": "woche5.html#einleitung",
    "title": "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen",
    "section": "",
    "text": "Diese Analyse untersucht den Zusammenhang zwischen Body-Mass-Index (BMI) und dem Auftreten von Diabetes-Typ-2 bei Pima-Indianerinnen basierend auf einem Datensatz von Kaggle [1]. Die Haupthypothese ist:\n\\(H_0\\): Es besteht keine Assoziation zwischen dem Body-Mass-Index (BMI) und dem Auftreten von Diabetes-Typ-2 bei Pima-Indianerinnen.\nNeben dem primären Ziel der BMI-Analyse werden auch sekundäre Endpunkte wie Glukosekonzentration, Blutdruck, Hautdicke, Insulin, Alter und Schwangerschaftsanzahl untersucht.",
    "crumbs": [
      "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen"
    ]
  },
  {
    "objectID": "woche5.html#methoden",
    "href": "woche5.html#methoden",
    "title": "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen",
    "section": "2 Methoden",
    "text": "2 Methoden\n\n2.1 Studiendesign\n\nQuerschnittsstudie mit retrospektiver Datenanalyse\nDatenerhebung: Sekundärdatenauswertung des Pima-Indianer-Datensatzes\n\n\n\n2.2 Studienpopulation\n\nEinschlusskriterien: Erwachsene weibliche Pima-Indianerinnen\nAusschlusskriterien: Fehlende BMI-Werte\n\n\n\n2.3 Analysemethoden\n\nDeskriptive Statistik: Mittelwerte, Standardabweichungen, Häufigkeiten\nChi-Quadrat-Tests: Assoziation zwischen kategorialen Variablen und Diabetes-Status\nT-Tests: Unterschiede in kontinuierlichen Variablen zwischen Diabetikerinnen und Nicht-Diabetikerinnen\nLogistische Regression: Berechnung von Odds Ratios für BMI und andere Variablen\nROC-Analyse: Bewertung der Modellleistung für BMI",
    "crumbs": [
      "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen"
    ]
  },
  {
    "objectID": "woche5.html#ergebnisse",
    "href": "woche5.html#ergebnisse",
    "title": "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen",
    "section": "3 Ergebnisse",
    "text": "3 Ergebnisse\n\n3.1 Datenaufbereitung und initiale Datenanalyse (IDA)\n\n\nCode\n# import libraries\nimport pandas as pd\nfrom itables import init_notebook_mode, show\nimport plotly.graph_objects as go\nimport plotly.io as pio\nfrom typing import Tuple\nimport statsmodels.api as sm\nimport numpy as np\nfrom sklearn.metrics import roc_curve, auc\nfrom scipy.stats import chi2_contingency, ttest_ind\nimport matplotlib\n\ninit_notebook_mode(all_interactive=True)\n\n# Define color palette\nBENE_COLORS_DARK: Tuple[str, ...] = (\n    \"#47476b\",\n    \"#6B5706\",\n    \"#206260\",\n    \"#93003a\",\n    \"#215F80\",\n    \"#973C2B\",\n    \"#008381\",\n    \"#6d3d3d\",\n    \"#595865\",\n)\nBENE_COLORS_LIGHT: Tuple[str, ...] = (\n    \"#7171A7\",\n    \"#B29211\",\n    \"#3BA4A0\",\n    \"#E80060\",\n    \"#3D9ED2\",\n    \"#FC6914\",\n    \"#00B2B0\",\n    \"#A96262\",\n    \"#9593A8\",\n)\n\npio.templates[\"bene\"] = go.layout.Template(\n    layout=go.Layout(\n        colorway=BENE_COLORS_LIGHT, paper_bgcolor=\"#222\", plot_bgcolor=\"#222\"\n    )\n)\npio.templates.default = \"plotly_dark+bene\"\n\n\ndef set_transparency(hex_color: str, transparency: float) -&gt; str:\n    \"\"\"\n    Set the transparency of a hex color.\n\n    Parameters:\n    hex_color (str): The hex color code (e.g., \"#47476b\").\n    transparency (float): The transparency level (0.0 to 1.0).\n\n    Returns:\n    str: The RGBA color code.\n    \"\"\"\n    if hex_color.startswith(\"#\"):\n        hex_color = hex_color[1:]\n\n    # Convert hex to RGB\n    r = int(hex_color[0:2], 16)\n    g = int(hex_color[2:4], 16)\n    b = int(hex_color[4:6], 16)\n\n    # Return the RGBA color\n    return f\"rgba({r}, {g}, {b}, {transparency})\"\n\ndef find_p_break(p_value: float, current_min_break:float, precision: int) -&gt; float:\n    if (p_value &lt; current_min_break) and (p_value &gt; current_min_break/10):\n        return current_min_break, precision\n    else:\n        return find_p_break(p_value, current_min_break/10, precision+1)\n\n# Load dataset\n# Original from https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database (License: CC0: Public Domain)\ndf = pd.read_csv(\"diabetes.csv\")\n\n\n\n\n\n\n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nThis is the init_notebook_mode cell from ITables v2.2.4\n(you should not see this message - is your notebook trusted?)\n\n\n\n\nEs befinden sich insgesamt 768 Einträge im Datensatz. Eine erste deskriptive Analyse ist in Tabelle 1 dargestellt. Der Datensatz enthält die Variablen:\n\nBody-Mass-Index (BMI, \\(\\text{Gewicht in kg}/(\\text{Größe in m})^2\\))\nAnzahl der Schwangerschaften\nAlter\nGlukosekonzentration im Plasma 2 Stunden nach einem oralen Glukosetoleranztest (mg/dl)\nBlutdruck (mm Hg)\nHautdicke (Trizeps in mm)\nInsulinkonzentration im Serum (mu U/ml)\nDiabetes-Pedigree-Faktor (Funktion die das Diabetesrisiko aufgrund der Verwandtschaft bewertet)\nOutcome (0 = kein Diabetes, 1 = Diabetes)\n\n\n\nCode\ndf.describe().round(2)\n\n\n\n\n\n\n\n    \n      \n      Pregnancies\n      Glucose\n      BloodPressure\n      SkinThickness\n      Insulin\n      BMI\n      DiabetesPedigreeFunction\n      Age\n      Outcome\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\nTabelle 1: Deskriptive Statistik des Datensatzes\n\n\n\n\nIn einigen Variablen befinden sich Nullwerte, die entsprechend der Ausschlusskriterien entfernt werden sollten, um eine korrekte Analyse durchzuführen.\n\n\nCode\ndf_without_zero = df[\n    (df[\"Glucose\"] != 0)\n    & (df[\"BloodPressure\"] != 0)\n    & (df[\"SkinThickness\"] != 0)\n    & (df[\"Insulin\"] != 0)\n    & (df[\"BMI\"] != 0)\n    & (df[\"Age\"] != 0)\n]\ndf_without_zero_count = df_without_zero.count()[0]\n\n\nWürde man alle Patientinnen mit Nullwerten in einer der Variablen entfernen, hätte man dadurch nur noch 392 Datensätze. Die primäre Forschungsfrage beschäftigt sich mit dem BMI. Teilnehmerinnen mit einem BMI von 0 wurden entfernt. Bei anderen Nullwerten wird der Median verwendet, um den Datensatz nicht übermäßig zu verkleinern.\n\n\nCode\ndf = df[df[\"BMI\"] != 0]\ndf[\"Glucose\"] = df[\"Glucose\"].replace(0, df[\"Glucose\"].median())\ndf[\"BloodPressure\"] = df[\"BloodPressure\"].replace(0, df[\"BloodPressure\"].median())\ndf[\"SkinThickness\"] = df[\"SkinThickness\"].replace(0, df[\"SkinThickness\"].median())\ndf[\"Insulin\"] = df[\"Insulin\"].replace(0, df[\"Insulin\"].median())\ndf[\"Age\"] = df[\"Age\"].replace(0, df[\"Age\"].median())\n\n\nNach der Bereinigung umfasst der Datensatz 757 Einträge, die für die Analyse verwendet werden können (vgl. Tabelle 2).\n\n\nCode\ndf.describe()\n\n\n\n\n\n\n\n    \n      \n      Pregnancies\n      Glucose\n      BloodPressure\n      SkinThickness\n      Insulin\n      BMI\n      DiabetesPedigreeFunction\n      Age\n      Outcome\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\nTabelle 2: Deskriptive Statistik des Datensatzes nach Bereinigung\n\n\n\n\n\n3.1.1 Verteilung der Variablen\nAbbildung 1 zeigt die Verteilung der kontinuierlichen Variablen nach Diabetes-Status.\n\nCode\ndef create_boxplot(data: pd.DataFrame, var_name: str) -&gt; go.Figure:\n    fig = go.Figure()\n\n    for outcome in [0, 1]:\n        fig.add_trace(\n            go.Box(\n                y=data[data[\"Outcome\"] == outcome][var_name],\n                name=f\"{'Diabetes' if outcome == 1 else 'Kein Diabetes'}\",\n                marker_color=BENE_COLORS_LIGHT[3 if outcome == 1 else 2],\n            )\n        )\n\n    fig.update_layout(\n        yaxis_title=var_name,\n        showlegend=False,\n    )\n    return fig\n\nfor var in [\n    \"BMI\",\n    \"Pregnancies\",\n    \"Age\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"DiabetesPedigreeFunction\",\n]:\n    fig = create_boxplot(df, var)\n    fig.show()\n\n\n\n\n\n\n\n\n\n                                                \n\n\n(a) BMI\n\n\n\n\n\n\n\n\n                                                \n\n\n(b) Anzahl der Schwangerschaften\n\n\n\n\n\n\n\n\n\n\n                                                \n\n\n(c) Alter\n\n\n\n\n\n\n\n\n                                                \n\n\n(d) Glukose in mg/dl\n\n\n\n\n\n\n\n\n\n\n                                                \n\n\n(e) Blutdruck in mm Hg\n\n\n\n\n\n\n\n\n                                                \n\n\n(f) Hautdicke in mm\n\n\n\n\n\n\n\n\n\n\n                                                \n\n\n(g) Insulin in mu U/ml\n\n\n\n\n\n\n\n\n                                                \n\n\n(h) Diabetes-Pedigree-Faktor\n\n\n\n\n\n\n\nAbbildung 1: Verteilung der kontinuierlichen Variablen nach Diabetes-Status\n\n\n\nEinige Daten wurden in Gruppen eingeteilt, um die Analyse zu optimieren. Die Gruppen umfassen BMI-Kategorien (Tabelle 3), Anzahl der Schwangerschaften (Tabelle 4) und Alter (Tabelle 5).\n\n\nCode\n# Translate BMI to WHO categories\ndef get_bmi_category(bmi):\n    if bmi &lt; 18.5:\n        return \"Underweight\"\n    elif bmi &lt; 25:\n        return \"Normal\"\n    elif bmi &lt; 30:\n        return \"Overweight\"\n    else:\n        return \"Obese\"\n\ndf[\"BMI_Category\"] = df[\"BMI\"].apply(get_bmi_category)\ndf[\"BMI_Category\"] = pd.Categorical(\n    df[\"BMI_Category\"], categories=[\"Underweight\", \"Normal\", \"Overweight\", \"Obese\"], ordered=True\n)\n\n# Add pregnancy groups\ndef get_pregnancy_group(pregnancies):\n    if pregnancies == 0:\n        return \"0\"\n    elif pregnancies &lt;= 3:\n        return \"1-3\"\n    elif pregnancies &lt;= 6:\n        return \"4-6\"\n    else:\n        return \"&gt;6\"\n\n\ndf[\"Pregnancies_Group\"] = df[\"Pregnancies\"].apply(get_pregnancy_group)\ndf[\"Pregnancies_Group\"] = pd.Categorical(\n    df[\"Pregnancies_Group\"], categories=[\"0\", \"1-3\", \"4-6\", \"&gt;6\"], ordered=True\n)\n\n# Add age groups\ndef get_age_group(age: float) -&gt; str:\n    if age &lt; 30:\n        return \"&lt;30\"\n    elif age &lt;= 40:\n        return \"30-40\"\n    else:\n        return \"&gt;40\"\n\ndf[\"Age_Group\"] = df[\"Age\"].apply(get_age_group)\ndf[\"Age_Group\"] = pd.Categorical(\n    df[\"Age_Group\"], categories=[\"&lt;30\", \"30-40\", \"&gt;40\"], ordered=True\n)\n\n\n\n\nCode\ndf.groupby(\"BMI_Category\").agg(\n    {\"BMI\": \"count\", \"Outcome\": \"mean\"}\n).rename(columns={\"BMI\": \"Anzahl\", \"Outcome\": \"Diabetes Rate\"}).round(2).reset_index()\n\n\n\n\n\n\n\n    \n      \n      BMI_Category\n      Anzahl\n      Diabetes Rate\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\nTabelle 3: Gruppierung der Datensätze nach BMI-Kategorien\n\n\n\n\n\n\nCode\ndf.groupby(\"Pregnancies_Group\").agg(\n    {\"Pregnancies\": \"count\", \"Outcome\": \"mean\"}\n).rename(columns={\"Pregnancies\": \"Anzahl\", \"Outcome\": \"Diabetes Rate\"}).round(2).reset_index()\n\n\n\n\n\n\n\n    \n      \n      Pregnancies_Group\n      Anzahl\n      Diabetes Rate\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\nTabelle 4: Gruppierung der Datensätze nach Anzahl der Schwangerschaften\n\n\n\n\n\n\nCode\ndf.groupby(\"Age_Group\").agg(\n    {\"Age\": \"count\", \"Outcome\": \"mean\"}\n).rename(columns={\"Age\": \"Anzahl\", \"Outcome\": \"Diabetes Rate\"}).round(2).reset_index()\n\n\n\n\n\n\n\n    \n      \n      Age_Group\n      Anzahl\n      Diabetes Rate\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\nTabelle 5: Gruppierung der Datensätze nach Altersgruppen\n\n\n\n\n\n\n\n3.2 Statistische Analyse\n\n3.2.1 Chi-Quadrat-Tests\nDie Ergebnisse des Chi-Quadrat-Tests für die kategorialen Variablen BMI, Alter und Schwangerschaften sind in Tabelle 6 dargestellt. Alle Werte sind statistisch signifikant (\\(p&lt;0.05\\)), was auf eine Assoziation mit dem Diabetes-Status hinweist. Die primär zu untersuchende Variable, der BMI, zeigt dabei die stärkste Assoziation. Eine weitere Untersuchung der Residuen des Chi-Quadrat-Tests (vgl. Tabelle 7) für die einzelnen Gruppierungen in BMI, Alter und Anzahl an Schwangerschaften zeigt einige signifikante Unterschiede zwischen den Gruppen. Jedoch sind nur in den Gruppen Untergewicht der BMI-Kategorie (welche keinen Diabetes-Fall aufweist) und den Gruppen 0 und 4-6 der Anzahl an Schwangerschaften keine statistisch signifikanten Residuen (\\(&lt;-2\\) oder \\(&gt;2\\)) zu erkennen.\n\n\nCode\ndef perform_chi_square(data: pd.DataFrame, category: str) -&gt; tuple:\n    contingency_table = pd.crosstab(data[category], data[\"Outcome\"])\n    chi2, p_value, dof, expected_freq = chi2_contingency(contingency_table)\n    if p_value &lt; 0.05:\n        p_break, precision = find_p_break(p_value, 0.05, 2)\n        p_value = f\"&lt; {p_break:.{precision}f}\"\n    residuals = (contingency_table - expected_freq) / np.sqrt(expected_freq)\n    return p_value, residuals\n\n\np_bmi, residuals_bmi = perform_chi_square(df, \"BMI_Category\")\np_age, residuals_age = perform_chi_square(df, \"Age_Group\")\np_preg, residuals_preg = perform_chi_square(df, \"Pregnancies_Group\")\n\nchi_square_results = pd.DataFrame(\n    {\n        \"Category\": [\"BMI\", \"Age\", \"Pregnancies\"],\n        \"p-value\": [p_bmi, p_age, p_preg],\n    }\n)\n\nwith pd.option_context(\"display.float_format\", \"{.:2f}\".format):\n    show(chi_square_results, escape=False)\n\n\n\n\n\n\n\n    \n      \n      Category\n      p-value\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\nTabelle 6: Chi-Quadrat-Test p-Werte für kategoriale Variablen\n\n\n\n\n\n\nCode\nshow(\n    residuals_bmi.reset_index().style.background_gradient(\n        cmap=\"vanimo\", vmin=-4, vmax=4, axis=None\n    )\n)\nshow(residuals_age.style.background_gradient(cmap=\"vanimo\", vmin=-4, vmax=4, axis=None))\nshow(\n    residuals_preg.style.background_gradient(cmap=\"vanimo\", vmin=-4, vmax=4, axis=None)\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBMI_Category\n0\n1\n\n\n\n\nUnderweight\n0.872616\n-1.185558\n\n\nNormal\n3.545885\n-4.817532\n\n\nOverweight\n2.125121\n-2.887244\n\n\nObese\n-3.037394\n4.126683\n\n\n\n\n\n(a) BMI-Kategorien\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutcome\n0\n1\n\n\nAge_Group\n \n \n\n\n\n\n&lt;30\n3.299210\n-4.482392\n\n\n30-40\n-1.755020\n2.384416\n\n\n&gt;40\n-3.004954\n4.082609\n\n\n\n\n\n(b) Altersgruppen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutcome\n0\n1\n\n\nPregnancies_Group\n \n \n\n\n\n\n0\n-0.005998\n0.008149\n\n\n1-3\n2.392820\n-3.250948\n\n\n4-6\n0.074574\n-0.101319\n\n\n&gt;6\n-3.341211\n4.539456\n\n\n\n\n\n(c) Schwangerschaftsgruppen\n\n\n\n\n\n\n\n\n\nTabelle 7: Residuen des Chi-Quadrat-Tests\n\n\n\n\n\n\n3.2.2 T-Tests\nFür die kontinuierlichen Variablen wurden t-Tests durchgeführt, um Unterschiede zwischen Diabetikerinnen und Nicht-Diabetikerinnen zu untersuchen. Die Ergebnisse sind in Tabelle 8 dargestellt. Die Variablen Glukose, BMI, Alter und Diabetes-Pedigree-Faktor zeigen signifikante Unterschiede zwischen den Gruppen (\\(p&lt;0.05\\)).\n\n\nCode\ndef perform_t_test(data: pd.DataFrame, variable: str) -&gt; float:\n    diabetic = data[data[\"Outcome\"] == 1][variable]\n    non_diabetic = data[data[\"Outcome\"] == 0][variable]\n    t_stat, p_value = ttest_ind(diabetic, non_diabetic)\n    return p_value\n\n\ncontinuous_vars = [\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"DiabetesPedigreeFunction\",\n]\np_values = []\nfor var in continuous_vars:\n    p_value = perform_t_test(df, var)\n    if p_value &lt; 0.05:\n        p_break, precision = find_p_break(p_value, 0.05, 2)\n        p_value = f\"&lt; {p_break:.{precision}f}\"\n    p_values.append(p_value)\n\ndf_t_test = pd.DataFrame(\n    {\n        \"Variable\": continuous_vars,\n        \"p-value\": p_values,\n    }\n)\ndf_t_test\n\n\n\n\n\n\n\n    \n      \n      Variable\n      p-value\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\nTabelle 8: P-Werte des t-Tests für kontinuierliche Variablen\n\n\n\n\n\n\n3.2.3 Logistische Regression und Odds Ratio für BMI\n\n\nCode\ndef calculate_odds_ratio(data: pd.DataFrame, var: str) -&gt; tuple:\n    X = sm.add_constant(data[var])\n    model = sm.Logit(data[\"Outcome\"], X).fit(disp=0)\n    odds_ratio = np.exp(model.params[var])\n    conf_int = np.exp(model.conf_int().iloc[1])\n    return odds_ratio, conf_int[0], conf_int[1], model\n\nodds_ratio_bmi, ci_lower_bmi, ci_upper_bmi, lr_result_bmi = calculate_odds_ratio(df, \"BMI\")\n\nfpr, tpr, _thresholds = roc_curve(\n    df[\"Outcome\"], df[\"BMI\"].apply(lambda x: lr_result_bmi.predict([1, x])[0])\n)\nauc_wert = float(auc(fpr, tpr))\n\n\nMittels logistischer Regression wurde der Zusammenhang zwischen BMI und Diabetes-Risiko untersucht (Abbildung 2). Die berechnete Odds Ratio für den BMI beträgt ≈1.11, was bedeutet, dass mit jedem Anstieg des BMI um einen Punkt das Diabetes-Risiko um 11% steigt. Das 95%-Konfidenzintervall für den Odds Ratio liegt zwischen ≈1.08 und ≈1.14. Die ROC-Kurve (Abbildung 3) und der AUC-Wert von ≈0.69 zeigen die moderate Diskriminierungsfähigkeit des BMI-basierten Modells.\n\n\nCode\nbmi_range = np.arange(df[\"BMI\"].min(), df[\"BMI\"].max(), 0.01)\n\n# Berechnung der Wahrscheinlichkeiten für den Bereich der BMI-Werte\nprobabilities = 1 / (\n    1 + np.exp(-(lr_result_bmi.params[\"const\"] + lr_result_bmi.params[\"BMI\"] * bmi_range))\n)\n\n# Calculate predictions for bmi_range\nbmi_with_const = sm.add_constant(bmi_range)\n\n# Convert to numpy arrays for matrix operations\nbmi_with_const_np = np.asarray(bmi_with_const)\ncov_matrix_np = np.asarray(lr_result_bmi.cov_params())\n\n# Calculate variance of the predictions\nvar_predictions = np.einsum('ij,jk,ik-&gt;i', bmi_with_const_np, cov_matrix_np, bmi_with_const_np)\n\n# Compute standard errors\nstd_errors = np.sqrt(var_predictions)\n\n# Calculate predictions\nmean = lr_result_bmi.predict(bmi_with_const)\n\n# 95% Confidence Interval calculation\nz_value = 1.96  # for 95% confidence level\nci_upper = mean + z_value * std_errors\nci_lower = mean - z_value * std_errors\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x=bmi_range,\n        y=probabilities,\n        mode=\"lines\",\n        name=\"Logistische Regression\",\n        line=dict(color=BENE_COLORS_LIGHT[0]),\n    )\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=np.concatenate([bmi_range, bmi_range[::-1]]),\n        y=np.concatenate([ci_upper, ci_lower[::-1]]),\n        fill='toself',\n        hoverinfo=\"skip\",\n        name='95% CI',\n        mode='none',\n        fillcolor=set_transparency(BENE_COLORS_LIGHT[0], 0.25),\n    )\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=df[\"BMI\"][df[\"Outcome\"] == 1],\n        y=df[\"Outcome\"][df[\"Outcome\"] == 1],\n        mode=\"markers\",\n        name=\"Diabetes-Typ-2\",\n        marker_symbol=\"diamond\",\n        marker_size=5,\n        line_color=set_transparency(BENE_COLORS_LIGHT[3], 0.5),\n    )\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=df[\"BMI\"][df[\"Outcome\"] == 0],\n        y=df[\"Outcome\"][df[\"Outcome\"] == 0],\n        mode=\"markers\",\n        name=\"kein Diabetes-Typ-2\",\n        marker_symbol=\"diamond\",\n        marker_size=5,\n        line_color=set_transparency(BENE_COLORS_LIGHT[2], 0.5),\n    )\n)\nfig.update_layout(\n    xaxis_title=\"BMI\",\n    yaxis_title=\"Outcome\",\n    xaxis=dict(range=[df[\"BMI\"].min(), df[\"BMI\"].max()], constrain=\"domain\", fixedrange=True),\n)\n\nfig.show()\n\n\n\n\n                                                \n\n\nAbbildung 2: Logistische Regressionskurve für BMI und Diabetes-Typ-2\n\n\n\n\n\n\nCode\nfig = go.Figure()\n\nfig.add_shape(\n    type=\"line\", line_dash=\"dash\", fillcolor=\"grey\", x0=0, x1=1, y0=0, y1=1\n)\nfig.add_trace(\n    go.Scatter(\n        x=fpr,\n        y=tpr,\n        mode=\"lines\",\n        name=f\"ROC Kurve (AUC = {auc_wert:.2f})\",\n        line_color=BENE_COLORS_LIGHT[0],\n        fill=\"tozeroy\",\n        fillcolor=set_transparency(BENE_COLORS_LIGHT[0], 0.25),\n    )\n)\nfig.update_layout(\n    xaxis_title=\"1 - Spezifität\",\n    yaxis_title=\"Sensitivität\",\n    xaxis=dict(range=[0, 1], constrain=\"domain\", fixedrange=True),\n    yaxis=dict(\n        range=[0, 1], scaleanchor=\"x\", scaleratio=1, constrain=\"domain\", fixedrange=True\n    ),\n    showlegend=False,\n)\nfig.show()\n\n\n\n\n                                                \n\n\nAbbildung 3: ROC-Kurve für das BMI-basierte Modell\n\n\n\n\n\n\n3.2.4 Odds Ratios für weitere kontinuierliche Variablen\nUm die Odds Ratios für die weiteren kontinuierlichen Variablen zu berechnen und vergleichbar zu machen, wurden die Variablen standardisiert und die logistische Regression durchgeführt. Die Ergebnisse sind in Abbildung 4 dargestellt. Glukose zeigt den stärksten Zusammenhang mit Diabetes, gefolgt von BMI. Alle Variablen haben signifikante Odds-Ratios und Konfidenzintervalle (\\(&gt;1\\)), die auf eine positive Korrelation zu Diabetes-Typ-2 hinweisen.\n\n\nCode\n# Berechnung der Odds Ratios auf standardisierten Variablen\ndef calculate_odds_ratio_std(data: pd.DataFrame, var: str) -&gt; tuple:\n    data_std = data.copy()\n    data_std[var] = (data_std[var] - data_std[var].mean()) / data_std[var].std()\n    X = sm.add_constant(data_std[var])\n    model = sm.Logit(data_std[\"Outcome\"], X).fit(disp=0)\n    odds_ratio = np.exp(model.params[var])\n    conf_int = np.exp(model.conf_int().loc[var])\n    return odds_ratio, conf_int[0], conf_int[1], model\n\n# Liste der Variablen\nvariables = [\n    \"BMI\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"DiabetesPedigreeFunction\",\n    \"Age\",\n]\n\n# Berechnung der Odds Ratios mittels der Standardisierung\nodds_ratios = []\nlower_cis = []\nupper_cis = []\nfor var in variables:\n    or_value, ci_lower, ci_upper, _ = calculate_odds_ratio_std(df, var)\n    odds_ratios.append(or_value)\n    lower_cis.append(ci_lower)\n    upper_cis.append(ci_upper)\n\n# Erstellung des Forest Plots\nfig = go.Figure()\n\n# Vertikale Linie bei OR = 1\nfig.add_shape(\n    type=\"line\",\n    x0=1,\n    x1=1,\n    y0=-1,\n    y1=len(variables),\n    line=dict(color=\"grey\", dash=\"dash\"),\n)\n\n# Odds Ratios und Konfidenzintervalle plotten\nfig.add_trace(\n    go.Scatter(\n        x=odds_ratios,\n        y=variables,\n        mode=\"markers\",\n        error_x=dict(\n            type=\"data\",\n            symmetric=False,\n            array=[up - or_val for up, or_val in zip(upper_cis, odds_ratios)],\n            arrayminus=[or_val - low for low, or_val in zip(lower_cis, odds_ratios)],\n        ),\n        marker=dict(color=BENE_COLORS_LIGHT[0], size=8, symbol=\"diamond\"),\n        name=\"Odds Ratio (standardisiert)\",\n    )\n)\n\nfig.update_layout(\n    xaxis_title=\"Odds Ratio (log scale)\",\n    yaxis_title=\"Variable\",\n    xaxis_type=\"log\",\n    showlegend=False,\n)\n\nfig.show()\n\n\n\n\n                                                \n\n\nAbbildung 4: Forest Plot der normalisierten Odds Ratios für kontinuierliche Variablen",
    "crumbs": [
      "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen"
    ]
  },
  {
    "objectID": "woche5.html#diskussion",
    "href": "woche5.html#diskussion",
    "title": "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen",
    "section": "4 Diskussion",
    "text": "4 Diskussion\n\n4.1 Limitationen\nDie vorliegende Analyse weist mehrere Limitationen auf, die bei der Interpretation der Ergebnisse berücksichtigt werden müssen. Zum einen verhindert das Querschnittsdesign jegliche kausale Schlussfolgerung. Da die Erhebung der Daten zu einem einzigen Zeitpunkt erfolgte, können Zusammenhänge zwischen Variablen nur als assoziativ betrachtet werden.\nEin weiterer wesentlicher Punkt ist der Selektionsbias. Die Ergebnisse basieren ausschließlich auf einer spezifischen Population von Pima-Indianerinnen, weshalb die Übertragbarkeit der Resultate auf andere Bevölkerungsgruppen oder geografische Regionen eingeschränkt sein könnte. Darüber hinaus könnte die Auswahl der Patientinnen selbst durch unterschiedliche Einschlusskriterien weiter verzerrt sein.\nDie Datenqualität stellt ein zusätzliches Problem dar, da fehlende Werte mit dem Median imputiert wurden. Diese Methode verringert zwar die Anzahl fehlender Daten, könnte jedoch zu einer Unterschätzung oder Überschätzung der wahren Varianz der Messwerte führen. Hier wäre eine detailliertere Analyse der fehlenden Werte oder eine andere Imputationsmethode, wie z.B. Nearest Neighbors Imputation [2] sinnvoll.\nNicht zuletzt sind potenzielle Confounding-Faktoren, wie Ernährungsgewohnheiten und körperliche Aktivität, in der Analyse nicht berücksichtigt worden. Diese nicht erfassten Variablen könnten die beobachteten Zusammenhänge zwischen BMI, anderen Risikofaktoren und dem Diabetes-Risiko beeinflussen und sollten in zukünftigen Untersuchungen genauer untersucht werden.\n\n\n4.2 Interpretation der Ergebnisse\nDie Analyse bestätigt einen signifikanten Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen, weshalb die Nullhypothese verworfen werden kann. Neben dem BMI zeigen die deskriptiven Statistiken, Chi‑Quadrat-Tests und t‑Tests, dass auch andere Variablen wie Glukose, Alter, Blutdruck und der Diabetes-Pedigree-Faktor wichtige Prädiktoren für das Diabetes-Risiko darstellen könnten. Insbesondere der Glukose-Wert ist aber wahrschinlich eine Folge des Diabetes und nicht ein Prädiktor.\nInsbesondere weisen die Chi‑Quadrat-Tests darauf hin, dass die Kategorisierung von BMI, Altersgruppen und Schwangerschaftszahlen statistisch signifikante Unterschiede zwischen Diabetikerinnen und Nicht-Diabetikerinnen offenbart. Die t‑Tests bestätigen signifikante Differenzen in den Mittelwerten kontinuierlicher Variablen zwischen den Variablen.\nDie logistische Regression liefert einen quantitativen Zusammenhang: Mit jedem Punktanstieg des BMI steigt das Risiko für Diabetes signifikant an, was durch den berechneten Odds Ratio untermauert wird. Zudem zeigt die ROC-Analyse des BMI-basierten Modells eine moderate Diskriminierungsfähigkeit, und der Forest Plot der standardisierten Odds Ratios verdeutlicht, dass insbesondere hohe Glukosewerte den stärksten Zusammenhang zu Diabetes-Typ-2 haben, während auch andere Variablen ihre Relevanz besitzen.\nEine weiterführende multivariate Analyse könnte zudem die komplexen Interaktionen zwischen den einzelnen Risikofaktoren detaillierter beleuchten.",
    "crumbs": [
      "Querschnittsstudie zum Zusammenhang zwischen BMI und Diabetes-Typ-2 bei Pima-Indianerinnen"
    ]
  }
]